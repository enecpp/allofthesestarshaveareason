using allofthesestarshaveareason.Models;
using allofthesestarshaveareason.Services.Interfaces;
using Microsoft.AspNetCore.Hosting;
using Microsoft.ML.OnnxRuntime;
using Microsoft.ML.OnnxRuntime.Tensors;
using Microsoft.ML.Tokenizers; 

namespace allofthesestarshaveareason.Services.Implementations;

public class OnnxTextAnalysisService : ITextAnalysisService, IDisposable
{
    private readonly InferenceSession _session;
    private readonly Tokenizer _tokenizer;
    private readonly ILogger<OnnxTextAnalysisService> _logger;
    private bool _disposed;

    public OnnxTextAnalysisService(IWebHostEnvironment env, ILogger<OnnxTextAnalysisService> logger)
    {
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
        ArgumentNullException.ThrowIfNull(env);

        try
        {
            // Modeli ve tokenizer'ı yükle
            var modelPath = Path.Combine(env.ContentRootPath, "wwwroot", "ml-models", "model.onnx");
            var vocabPath = Path.Combine(env.ContentRootPath, "wwwroot", "ml-models", "vocab.txt");

            if (!File.Exists(modelPath))
            {
                throw new FileNotFoundException($"ONNX model file not found at: {modelPath}");
            }

            if (!File.Exists(vocabPath))
            {
                throw new FileNotFoundException($"Vocabulary file not found at: {vocabPath}");
            }

            _session = new InferenceSession(modelPath);
            _tokenizer = new BertTokenizer(vocabPath, lowercase: true);
            
            _logger.LogInformation("ONNX model and tokenizer loaded successfully");
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to initialize OnnxTextAnalysisService");
            throw;
        }
    }

    public async Task<List<SentenceEmbedding>> GenerateEmbeddingsAsync(List<TranscriptSegment> segments)
    {
        ObjectDisposedException.ThrowIf(_disposed, this);
        ArgumentNullException.ThrowIfNull(segments);

        if (segments.Count == 0)
        {
            _logger.LogWarning("No segments provided for embedding generation");
            return new List<SentenceEmbedding>();
        }

        return await Task.Run(() =>
        {
            try
            {
                var embeddings = new List<SentenceEmbedding>();
                var segmentTexts = segments.Select(s => s.Text ?? string.Empty).ToList();

                // 1. ADIM: TOKENIZATION
                // Tüm cümleleri modelin anlayacağı sayısal ID'lere dönüştür.
                var encodedBatch = _tokenizer.EncodeBatch(segmentTexts);

                for (int i = 0; i < encodedBatch.Count; i++)
                {
                    var encoded = encodedBatch[i];
                    
                    // 2. ADIM: TENSOR OLUŞTURMA
                    var inputIds = ConvertToTensor(encoded.Ids);
                    var attentionMask = ConvertToTensor(encoded.AttentionMask);
                    var tokenTypeIds = ConvertToTensor(encoded.TypeIds);

                    var inputs = new List<NamedOnnxValue>
                    {
                        NamedOnnxValue.CreateFromTensor("input_ids", inputIds),
                        NamedOnnxValue.CreateFromTensor("attention_mask", attentionMask),
                        NamedOnnxValue.CreateFromTensor("token_type_ids", tokenTypeIds)
                    };

                    // 3. ADIM: MODELİ ÇALIŞTIRMA (INFERENCE)
                    using var results = _session.Run(inputs);

                    // 4. ADIM: SONUCU İŞLEME (MEAN POOLING)
                    var lastHiddenState = results.First().AsTensor<float>();
                    var pooledVector = MeanPooling(lastHiddenState, encoded.AttentionMask);

                    embeddings.Add(new SentenceEmbedding
                    {
                        SegmentId = $"segment_{i}",
                        Vector = pooledVector
                    });
                }

                _logger.LogInformation("Generated {Count} embeddings successfully", embeddings.Count);
                return embeddings;
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error generating embeddings");
                throw new InvalidOperationException("Failed to generate embeddings", ex);
            }
        }).ConfigureAwait(false);
    }

    public List<TranscriptSegment> FindSimilarSentences(
        string query, 
        List<TranscriptSegment> allSegments, 
        List<SentenceEmbedding> allEmbeddings)
    {
        ObjectDisposedException.ThrowIf(_disposed, this);
        ArgumentNullException.ThrowIfNull(query);
        ArgumentNullException.ThrowIfNull(allSegments);
        ArgumentNullException.ThrowIfNull(allEmbeddings);

        if (string.IsNullOrWhiteSpace(query))
        {
            _logger.LogWarning("Empty query provided for similarity search");
            return new List<TranscriptSegment>();
        }

        if (allSegments.Count == 0 || allEmbeddings.Count == 0)
        {
            return new List<TranscriptSegment>();
        }

        try
        {
            // 1. Arama sorgusunu da aynı şekilde vektöre dönüştür.
            var queryEmbedding = GenerateEmbeddingsForSingleText(query);
            if (queryEmbedding == null || queryEmbedding.Length == 0)
            {
                _logger.LogWarning("Failed to generate embedding for query");
                return new List<TranscriptSegment>();
            }

            // 2. Benzerlik skorlarını hesapla
            var scoredSegments = new List<(TranscriptSegment segment, double score)>();
            int segmentCount = Math.Min(allSegments.Count, allEmbeddings.Count);
            
            for (int i = 0; i < segmentCount; i++)
            {
                var score = CosineSimilarity(queryEmbedding, allEmbeddings[i].Vector);
                scoredSegments.Add((allSegments[i], score));
            }

            // 3. Skorlara göre sırala ve en alakalı olanları döndür
            var results = scoredSegments
                .OrderByDescending(s => s.score)
                .Take(5) // En iyi 5 sonucu al
                .Select(s => s.segment)
                .ToList();

            _logger.LogInformation("Found {Count} similar segments for query", results.Count);
            return results;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error finding similar sentences");
            return new List<TranscriptSegment>();
        }
    }

    // Tek bir metin için embedding oluşturan yardımcı metot
    private float[]? GenerateEmbeddingsForSingleText(string text)
    {
        try
        {
            var encoded = _tokenizer.Encode(text);
            
            var inputIds = ConvertToTensor(encoded.Ids);
            var attentionMask = ConvertToTensor(encoded.AttentionMask);
            var tokenTypeIds = ConvertToTensor(encoded.TypeIds);

            var inputs = new List<NamedOnnxValue>
            {
                NamedOnnxValue.CreateFromTensor("input_ids", inputIds),
                NamedOnnxValue.CreateFromTensor("attention_mask", attentionMask),
                NamedOnnxValue.CreateFromTensor("token_type_ids", tokenTypeIds)
            };

            using var results = _session.Run(inputs);
            var lastHiddenState = results.First().AsTensor<float>();
            return MeanPooling(lastHiddenState, encoded.AttentionMask);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error generating embedding for text");
            return null;
        }
    }

    // IReadOnlyList<int>? to DenseTensor<long> converter
    private static DenseTensor<long> ConvertToTensor(IReadOnlyList<int>? ids)
    {
        if (ids == null || ids.Count == 0)
        {
            return new DenseTensor<long>(new long[] { 0 }, new[] { 1, 1 });
        }

        var longArray = ids.Select(x => (long)x).ToArray();
        return new DenseTensor<long>(longArray, new[] { 1, longArray.Length });
    }

    // Model çıktısını anlamlı bir cümle vektörüne dönüştüren metot
    private float[] MeanPooling(Tensor<float> tokenEmbeddings, IReadOnlyList<int>? attentionMask)
    {
        if (attentionMask == null || attentionMask.Count == 0)
        {
            return Array.Empty<float>();
        }

        int tokenCount = attentionMask.Count;
        int embeddingDim = (int)(tokenEmbeddings.Length / tokenCount);
        var pooled = new float[embeddingDim];
        int validTokenCount = 0;

        for (int i = 0; i < tokenCount; i++)
        {
            if (attentionMask[i] == 1) // Sadece gerçek token'ları (padding olmayanları) hesaba kat
            {
                validTokenCount++;
                for (int j = 0; j < embeddingDim; j++)
                {
                    int index = i * embeddingDim + j;
                    if (index < tokenEmbeddings.Length)
                    {
                        pooled[j] += tokenEmbeddings.GetValue(index);
                    }
                }
            }
        }

        if (validTokenCount == 0)
        {
            return pooled;
        }

        for (int j = 0; j < embeddingDim; j++)
        {
            pooled[j] /= validTokenCount;
        }

        return pooled;
    }

    // İki vektör arasındaki anlamsal yakınlığı ölçen metot
    private static double CosineSimilarity(float[] vec1, float[] vec2)
    {
        ArgumentNullException.ThrowIfNull(vec1);
        ArgumentNullException.ThrowIfNull(vec2);

        if (vec1.Length != vec2.Length)
        {
            throw new ArgumentException("Vectors must have the same length");
        }

        if (vec1.Length == 0)
        {
            return 0.0;
        }

        double dotProduct = 0.0;
        double mag1 = 0.0;
        double mag2 = 0.0;

        for (int i = 0; i < vec1.Length; i++)
        {
            dotProduct += vec1[i] * vec2[i];
            mag1 += vec1[i] * vec1[i];
            mag2 += vec2[i] * vec2[i];
        }

        var magnitude = Math.Sqrt(mag1) * Math.Sqrt(mag2);
        return magnitude == 0 ? 0.0 : dotProduct / magnitude;
    }

    public void Dispose()
    {
        if (_disposed)
        {
            return;
        }

        _session?.Dispose();
        _disposed = true;
        
        GC.SuppressFinalize(this);
        _logger.LogInformation("OnnxTextAnalysisService disposed");
    }
}